{"cells":[{"cell_type":"markdown","metadata":{"id":"bHohU-c4bvCX"},"source":["### Importing Class Similarities Data\n","\n","First we will import some modules that we might need ðŸ˜‰"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfEshs0HwdMU"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn import preprocessing\n","from sklearn.metrics import pairwise_distances\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n","from sklearn.metrics import mean_squared_error\n","\n"]},{"cell_type":"markdown","source":["##Part 1: Exploring the Data\n","\n","\n","Now lets read in the data from the ClassSimilarities_2025Spring.csv matrix. [Click here to download the data](https://drive.google.com/uc?download&id=1KHm51Dv09t9bcSaJbSn8eCBLY8ZUsdj2)"],"metadata":{"id":"wzNlN3-Xb2zo"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"xWkZKV03wk99"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4n0KZnupvuG8"},"outputs":[],"source":["# read in data\n","sims = pd.read_csv('ClassSimilarities_2025Spring.csv')\n","sims.head()\n"]},{"cell_type":"code","source":["# frequency table of values for Section\n","sims['Section'].value_counts()\n"],"metadata":{"id":"zKaVejYP4Gf-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4GsiUTumvuG8"},"source":["Uncomment the line for your class and create the `class_df` data frame\n","Call your matrix \"class_df\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvGlKrJovuG9"},"outputs":[],"source":["\n","#class_df = sims[sims['Section'] == 'Section 1 (MW 930am)']\n","#class_df = sims[sims['Section'] == 'Section 2 (MW 11am)']\n","#class_df = sims[sims['Section'] == 'Section 30 (W 6pm)']\n","\n","class_df.shape"]},{"cell_type":"markdown","source":["Explore the features of interest.  \n","Sort by the mean to see which features are most (and least) popular.  Maybe even sort hightest to lowest!\n"],"metadata":{"id":"2FwNz9k3D6FC"}},{"cell_type":"code","source":["# Place code here"],"metadata":{"id":"RqXS6lQCVNvl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Plot barplots to visualize the distributions of each of the features.\n","\n","Suggestion - define the columns of interest as `feature_cols` and use a for loop to iterate over all of the features of interest and plot a barplot.\n","\n","Try and get the barplot to plot in order from 1 to 5 on the x-axis. (can use \"reindex\" for this)"],"metadata":{"id":"u1t2m-ncVOWT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRzS0MutvuG9"},"outputs":[],"source":["# Place code here\n","\n"]},{"cell_type":"markdown","source":["Plot a heatmap of the correlations to see which features are most positively and negatively correlated.  Use the `.corr()` function in seaborn and `sns.heatmap`.  Any interesting results here?\n","\n","*you can play with colorbrewer colors here!  My favorite is cmap='RdBu_r' and dont forget to set the limits to (-1,1) using `vmax` and `vmin`*"],"metadata":{"id":"PUdMeysdElfH"}},{"cell_type":"code","source":["# Place code here"],"metadata":{"id":"LyY-w_rjGH2S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now plot a histogram of caffeine cups per week (`CoffeeTeaSoda`).  How many zeros are there?\n","\n","How many people dont drink any caffeine? ðŸ˜²"],"metadata":{"id":"7VFIz5h2GIlL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KilJ8IGjvuG9"},"outputs":[],"source":["# Place code here\n"]},{"cell_type":"markdown","metadata":{"id":"HT6HBKSbvuG-"},"source":["\n","## Part 2: Looking at distances between students\n","\n","One helpful suggestions would be to set *NYUID* as the index so that you can easily extract the data for any given  NYUID."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ye2bHx8qvuG-"},"outputs":[],"source":["\n","# Set 'NYUID' as the index - this allows you to call the row by the NYUID\n","class_df.set_index('NYUID', inplace=True)\n"]},{"cell_type":"markdown","source":["Use `sklearn.pairwise_distances` (already installed above) to calculate a distance matrix \"dist_matrix\"  (It may be helpful to convert the dist_matrix into a data frame using pd.DataFrame)\n","\n","Use Manhattan distance because it will be more iterpretable.\n","\n","Identify your data with your NYUID and see if you can find the three most similar students to you and the three least similar students to you"],"metadata":{"id":"PbKY_MobJF9U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4_xxD-KDvuG-"},"outputs":[],"source":["# Place code here\n","\n","input_NYUID='YOUR_ID_HERE'"]},{"cell_type":"markdown","source":["Find the three most similar students to you and the three least similar students to you.\n","\n","Remember that the most similar student will be the student themself!  (distance = 0) so you will have to account for that.\n","\n","also you might want to check to make sure that the input_NYUID is actuall in the index or else you will get an error."],"metadata":{"id":"3q89cchqJqAy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Uj_GvTfbvCZ"},"outputs":[],"source":["if (input_NYUID in class_df.index):\n","\n","    # Get the distances for the input NYUID\n","\n","    # Get the 3 most similar students (excluding the input student itself)\n","\n","    # Get the 3 least similar students\n","\n","    # Print the NYUID and Name of the most and least similar students\n","\n","else:\n","    print('NYUID not found in the dataset')\n"]},{"cell_type":"markdown","metadata":{"id":"P1w9ICxQvuG_"},"source":["Which two people in the class are overall the closest?  Because we use Manhattan distance, this distance is interpreted as the total sum of the absolute differences of the 24 features.\n","\n","You can look for the smallest value in the matrix, but you need to account for the fact that the diagonals are zero...\n","\n","this one is tricky, you may need to use `unravel_index` to find the row and col in the matrix with the lowest value...(see solution - although there are other ways to do this as well)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKZorjzuvuG_"},"outputs":[],"source":["# Place code here\n"]},{"cell_type":"markdown","source":["Which two people in the class are the furthest?"],"metadata":{"id":"DYMBsPP8LFMX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdLMDcpSvuG_"},"outputs":[],"source":["# Place code here"]},{"cell_type":"markdown","metadata":{"id":"quAZp6N5vuHA"},"source":["##Part 3: K nearest neighbors for predicting targets##\n","\n","We want to know if the preferences data has value in predicting the Coffee consumption or the Hours Sleep.\n","\n","Since we dont have a lot of data in each class, use the entire `sims` data (both classes) and split into 80/20 and fit a knn with k=5 (aka `KNeighborsRegressor(n_neighbors=5)`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2iEPf6YvuHA"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.model_selection import train_test_split\n","\n","# Select the features and target\n","X = sims[feature_cols]\n","y = sims['CoffeeTeaSoda']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(???)\n","\n","# Create a KNeighborsRegressor with k=5\n","\n","# Place Code Here"]},{"cell_type":"markdown","source":["Make a scatterplot of predicted values for the test set on the x-axis and actual values on the y-axis.\n","\n","Does the prediction seem any good?"],"metadata":{"id":"W97lg6a6PsY5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvPGL3vevuHA"},"outputs":[],"source":["# Place code here"]},{"cell_type":"markdown","source":["Using a for-loop - find the best k via RMSE."],"metadata":{"id":"M0xOMI38P8Hi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSKXRKmobvCa"},"outputs":[],"source":["#yikes this is not good!  But lets calcuate the best k anyway\n","from sklearn.metrics import mean_squared_error\n","\n","for k in range(1, 21):\n","  #Place code here\n"]},{"cell_type":"markdown","metadata":{"id":"nK3qYsvZbvCa"},"source":["##Part 4: Clustering\n"]},{"cell_type":"markdown","source":["Lets perform hierarchical clustering to find the \"10-cluster solution\" and print out the clusters.\n","\n","Did any of you end up in clusters with your project team members?\n","\n","All code provided...\n","\n","\n"],"metadata":{"id":"a6TJtxglQIVl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGBQZquYbvCa"},"outputs":[],"source":["from sklearn.cluster import AgglomerativeClustering\n","\n","# Create an AgglomerativeClustering model with 6 clusters\n","cluster = AgglomerativeClustering(n_clusters=10, linkage='ward')\n","\n","# Fit the model to the data and predict the cluster labels\n","cluster_labels = cluster.fit_predict(class_df[feature_cols])\n","student_clusters = class_df.assign(Cluster=cluster_labels)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LBGy3pVbvCa"},"outputs":[],"source":["\n","for cluster, data in student_clusters.groupby('Cluster'):\n","    print(f\"Cluster {cluster}:\")\n","    print(data.Name.tolist())\n","    print()"]},{"cell_type":"markdown","source":["Plot the dendrogram.\n","\n","Play around with the following  parameters:\n","in the linkage function : `method` and `metric`\n","\n","in the dendrogram: `orientation` - for the direction of the plot\n","                : `color_threshold` - for how the plot is colored showing different clusters\n","\n","can use `labels=class_df.index` to show NYUID instead of names...\n"],"metadata":{"id":"bcZ0f5gIQzdn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFT2c_zrbvCa"},"outputs":[],"source":["from scipy.cluster.hierarchy import dendrogram, linkage\n","\n","# Create a linkage matrix\n","linked = linkage(class_df[feature_cols], 'ward')\n","\n","# Plot the dendrogram\n","plt.figure(figsize=(10, 7))\n","dendrogram(linked, orientation='top', labels=class_df.Name, distance_sort='descending', show_leaf_counts=True)\n","plt.show()"]},{"cell_type":"markdown","source":["For fun - we can also cluster the *features* to see which are most similar...by passing the feature correlation matrix into the `linked` function"],"metadata":{"id":"5ondeyZMdn52"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3J_G-BgIbvCa"},"outputs":[],"source":["# Calculate the correlation matrix\n","corr = class_df[feature_cols].corr()\n","\n","# Create a linkage matrix based on the correlation matrix\n","linked = linkage(corr, 'ward')\n","\n","# Create a dendrogram\n","plt.figure(figsize=(10, 7))\n","dendrogram(linked, labels=corr.columns, orientation='right',color_threshold = 2)\n","plt.show()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1jmtPSZOtYeCMJaXle6hqxzMVLCWIXuhF","timestamp":1731204831616}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}