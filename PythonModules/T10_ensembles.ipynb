{"cells":[{"cell_type":"markdown","source":["## Ensembles\n","\n","The purpose of this module is to show the value of ensembles.  We will simulate predictors that have a given performance (accuracy) as a predictor of the target variable.  Then we will show that a combination of these does better than any individual one of them.\n","\n","First we will create a target variable.  Assume this is the target for a classification problem.  The target should have 50% 0s and 50% 1s."],"metadata":{"id":"MeirGsNEDHNc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BrZKgMRC0qI"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","\n","n=1000\n","# Create the target column with 50% 0s and 50% 1s\n","target = random.choices([0, 1], k=n)\n","df = pd.DataFrame({'target': target})\n"]},{"cell_type":"markdown","source":["Now we are going to use the following code to create \"predictors\" - think of these as the predictions that come out of a particular model, maybe separate trees or regression models.   \n","\n","We will keep the code generic, start with num_models = 3 (num_models should be an odd number)\n","\n","Each predictor is created so that the accuracy is specified (p).\n","\n","So, for instance if p=0.6, each of the predictors has 60% accuracy.  "],"metadata":{"id":"4ascbdAMDqqR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdb5CXbLC0qM"},"outputs":[],"source":["## now create k new columns each one having success probability p\n","p=.6\n","num_models=3 # keep this as an odd number to break ties later.\n","\n","for i in range(num_models):\n","    indices = random.sample(range(len(target)), int((1-p)*n))\n","    new_col = target.copy()\n","    for ix in indices:\n","        new_col[ix] = 1 - target[ix]\n","    df['pred'+str(i+1)] = new_col\n","\n","\n"]},{"cell_type":"code","source":["df"],"metadata":{"id":"5hcqSlrBg942"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use sklearn.metrics to calculate the accuracy, precision and recall of pred1, pred2, and pred3.\n","\n","Lots of other metrics you can calculate also, see [scikit learn documentation.](https://scikit-learn.org/stable/modules/model_evaluation.html)\n"],"metadata":{"id":"mO_5YcX9GYh3"}},{"cell_type":"code","source":["# look at the performance of the first predictor, pred1\n","\n","f1 = round(metrics.f1_score(df['target'],df['pred1']),3)\n","prec = round(metrics.precision_score(df['target'],df['pred1']),3)\n","acc = round(metrics.accuracy_score(df['target'],df['pred1']),3)\n","rec = round(metrics.recall_score(df['target'],df['pred1']),3)\n","\n","print(\"f1 = \",f1,\"; accuracy =\",acc,\"precision = \",prec,\"; recall = \",rec)"],"metadata":{"id":"4kD9uh8UE4IB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, create a new ensemble column, `en_sum`, by summing up the values of the predictor vectors.  This represents the total number of models that predict the positive class.\n","\n","Then, create your ensemble predictor `en_pred` which is 1 if `en_sum` is greater than half the number of predictors (num_models), and 0 if not.\n"],"metadata":{"id":"xvBuke-zHreL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuYICFYiC0qN"},"outputs":[],"source":["en_sum = df.iloc[:, 1:].sum(axis=1)\n","en_pred = (en_sum > num_models/2).astype(int)"]},{"cell_type":"markdown","source":["Check the accuracy, precision, recall, and f1 of your new ensemble predictor `en_pred`.  How does it compare to the individual models?"],"metadata":{"id":"2LoBTwPCME3I"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDi9tTZdC0qO"},"outputs":[],"source":["f1 = round(metrics.f1_score(df['target'],en_pred),3)\n","prec = round(metrics.precision_score(df['target'],en_pred),3)\n","acc = round(metrics.accuracy_score(df['target'],en_pred),3)\n","rec = round(metrics.recall_score(df['target'],en_pred),3)\n","\n","print(\"f1 = \",f1,\"; accuracy =\",acc,\"precision = \",prec,\"; recall = \",rec)"]},{"cell_type":"markdown","source":["Now go back and change the number of models, and/or the success probability of the original model.  How does that impact the results?  "],"metadata":{"id":"rcL6VqWzMsux"}},{"cell_type":"markdown","source":["\n"],"metadata":{"id":"zvHroEFTPlOH"}},{"cell_type":"code","source":["n=1000\n","p=.6\n","# Create the target column with 50% 0s and 50% 1s\n","target = random.choices([0, 1], k=n)\n","df = pd.DataFrame({'target': target})\n","\n","max_models = 31\n","for i in range(max_models):\n","  indices = random.sample(range(len(target)), int((1-p)*n))\n","  new_col = target.copy()\n","  for ix in indices:\n","    new_col[ix] = 1 - target[ix]\n","    df['pred'+str(i+1)] = new_col\n","\n"],"metadata":{"id":"5-U47-7DPvjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1_results=[]\n","for num_models in np.arange(3,max_models+1,2):\n","  en_sum = df.iloc[:, 1:(num_models+1)].sum(axis=1)\n","  en_pred = (en_sum > num_models/2).astype(int)\n","  f1 = metrics.f1_score(df['target'],en_pred).round(3)\n","  f1_results.append(f1)\n","  print(num_models,f1)\n","\n","print(f1_results)\n","\n"],"metadata":{"id":"gAJcGLtQQbbX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(np.arange(3,max_models+1,2),f1_results)\n","plt.xlabel(\"Num Models\")\n","plt.ylabel(\"F Score\")\n","plt.xticks(np.arange(3,max_models+1,2))\n","plt.show()\n"],"metadata":{"id":"Saq6RCAXQOD-"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[{"file_id":"1jxpsjafwPnCBp9Q9v3bLaxP2lvgsAjtS","timestamp":1732230691858}]}},"nbformat":4,"nbformat_minor":0}